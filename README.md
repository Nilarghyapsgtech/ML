1.Data Understanding
2. Data Preparation
3.Modelling
4. Evaluation
5. Hyperparameter Tuning
6. Unit and Integration Testing
7. Deployment

Some of the packages to be used.

1. pandas
2. matplotlib
3. seaborn
4. sklearn
5. FastAPI
6. Streamlit
7. Jenkins
8. MLFlow
9. auto-sklearn
10. wandb

i) Data imputation techniques. - All given in blog

ii) Feature Selection
a) Data visualization
b) Recursive Feature Elimination (RFE)
c) SelectKBest
d) L1 Regularization (LASSO)
e) Tree-based methods: Feature Importance from Decision Trees or Random Forests
f) VarianceThreshold
g) Mutual Information
h) Sequential Feature Selection (SFS)

iii) Dimensionality Reduction: PCA

iv) Analyse the discrete and continuous variables and check result with discrete variables as one hot encoding

Create an excel with the following information.
A. Consider commonly used regressors like:

1. Linear Regression
2. Ridge Regression
3. Lasso Regression
4. Decision Tree Regressor
5. Random Forest Regressor
6. Gradient Boosting Regressor
7. XGBoost Regressor
8. Support Vector Regressor (SVR)
9. K-Nearest Neighbors Regressor (KNN)
10. Neural Network Regressor
11. Elastic Net
12. Bayesian Ridge Regression
13. Huber Regressor
14. Isotonic Regression
15. Gaussian Process Regressor
16. CatBoost Regressor
17. LightGBM Regressor
18. Elastic NetCV
19. LGBM Regressor
20. AdaBoost Regressor

B. Perform cross-validation

C. Tabulate result with multiple
i) Imputation techniques
ii) Feature selection techniques
iii) Dimensionality Reduction techniques
iv) Different parameters for each regressor

Note:
1. Give proper structure for directory as in industry
2. Use design patterns
3. Use pipelines. abstract methods, classes
4. Use linters
